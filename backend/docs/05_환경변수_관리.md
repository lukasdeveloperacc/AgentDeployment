# 환경변수 관리

## 환경변수란?

환경변수(Environment Variable)는 **애플리케이션 외부에서 설정값을 주입하는 방법**입니다. 코드에 하드코딩하지 않고 실행 환경에 따라 다른 설정을 사용할 수 있습니다.

### 왜 환경변수를 사용하는가?

1. **보안**
   - API 키, 비밀번호를 코드에 노출하지 않음
   - Git 저장소에 민감 정보 커밋 방지

2. **유연성**
   - 개발/스테이징/프로덕션 환경별 설정 분리
   - 재빌드 없이 설정 변경 가능

3. **이식성**
   - 환경에 독립적인 코드
   - 다양한 배포 환경 지원

4. **12 Factor App 원칙**
   - 클라우드 네이티브 앱 표준
   - 환경 간 차이를 설정으로 분리

## 민감 정보 vs 일반 설정

### 민감 정보 (절대 Git에 커밋 금지)
- API 키: `OPENAI_API_KEY`, `PINECONE_API_KEY`
- 비밀번호: 데이터베이스 비밀번호
- 토큰: JWT Secret, OAuth 토큰
- 인증서: SSL/TLS 인증서

### 일반 설정 (커밋 가능)
- 포트 번호: `PORT=8000`
- 로그 레벨: `LOG_LEVEL=INFO`
- 기능 플래그: `FEATURE_ENABLED=true`
- 기본값: `DEFAULT_TIMEOUT=30`

## Python에서 환경변수 사용

### 1. os.environ (기본)

```python
import os

# 환경변수 읽기
api_key = os.environ["OPENAI_API_KEY"]  # 없으면 에러

# 기본값 제공
port = os.environ.get("PORT", "8000")  # 없으면 "8000"

# 타입 변환
debug = os.environ.get("DEBUG", "false").lower() == "true"
max_tokens = int(os.environ.get("MAX_TOKENS", "1000"))
```

### 2. python-dotenv

`.env` 파일에서 환경변수 자동 로드:

**`.env` 파일**:
```bash
# OpenAI 설정
OPENAI_API_KEY=sk-proj-your-api-key-here
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000

# Pinecone 설정
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_INDEX_NAME=ai-service-docs

# 서버 설정
PORT=8000
DEBUG=false
LOG_LEVEL=INFO

# CORS
CORS_ORIGINS=http://localhost:3000
```

**Python 코드**:
```python
from dotenv import load_dotenv
import os

# .env 파일 로드
load_dotenv()

# 환경변수 사용
api_key = os.getenv("OPENAI_API_KEY")
llm_model = os.getenv("LLM_MODEL", "gpt-4o-mini")
temperature = float(os.getenv("LLM_TEMPERATURE", "0.7"))
max_tokens = int(os.getenv("LLM_MAX_TOKENS", "1000"))

print(f"Using model: {llm_model}")
```

### 3. pydantic-settings (권장)

타입 안전하고 검증 가능한 설정:

```python
from pydantic_settings import BaseSettings
from pydantic import Field

class Settings(BaseSettings):
    # OpenAI
    openai_api_key: str = Field(..., description="OpenAI API Key")
    llm_model: str = Field(default="gpt-4o-mini")
    llm_temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    llm_max_tokens: int = Field(default=1000, gt=0)

    # Pinecone
    pinecone_api_key: str | None = None
    pinecone_index_name: str = "ai-service-docs"

    # Server
    port: int = Field(default=8000, gt=0, lt=65536)
    debug: bool = False
    log_level: str = Field(default="INFO", pattern="^(DEBUG|INFO|WARNING|ERROR)$")

    # CORS
    cors_origins: str = "http://localhost:3000"

    class Config:
        env_file = ".env"
        case_sensitive = False  # 대소문자 구분 안 함

# 설정 인스턴스 생성 (자동으로 .env 로드 및 검증)
settings = Settings()

# 사용
print(settings.llm_model)
print(settings.llm_temperature)
```

**장점**:
- ✅ 타입 안전성
- ✅ 자동 검증 (범위, 패턴 등)
- ✅ 기본값 명시적
- ✅ IDE 자동완성

## .env 파일 관리

### .env 파일 구조

```bash
# ================================
# OpenAI 설정
# ================================
OPENAI_API_KEY=sk-proj-xxxxx

# LLM 모델 선택: gpt-4o-mini, gpt-4o, gpt-4-turbo
LLM_MODEL=gpt-4o-mini

# Temperature: 0.0 (결정적) ~ 2.0 (창의적)
LLM_TEMPERATURE=0.7

# 최대 토큰 수
LLM_MAX_TOKENS=1000

# ================================
# Pinecone 설정 (RAG 사용 시)
# ================================
PINECONE_API_KEY=pcsk-xxxxx
PINECONE_INDEX_NAME=ai-service-docs

# ================================
# RAG 설정
# ================================
# 검색할 문서 개수
RAG_TOP_K=3

# Embedding 모델
EMBEDDING_MODEL=text-embedding-3-small

# ================================
# 서버 설정
# ================================
PORT=8000
DEBUG=false
LOG_LEVEL=INFO

# ================================
# CORS 설정
# ================================
# 쉼표로 구분된 도메인 목록
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
```

### .env.example (템플릿)

Git에 커밋할 템플릿 파일:

```bash
# ================================
# OpenAI 설정 (필수)
# ================================
# OpenAI API Key 발급: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your-api-key-here

LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000

# ================================
# Pinecone 설정 (RAG 사용 시 필수)
# ================================
# Pinecone API Key 발급: https://app.pinecone.io/
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_INDEX_NAME=ai-service-docs

# ================================
# RAG 설정
# ================================
RAG_TOP_K=3
EMBEDDING_MODEL=text-embedding-3-small

# ================================
# 서버 설정
# ================================
PORT=8000
DEBUG=false
LOG_LEVEL=INFO

# ================================
# CORS 설정
# ================================
CORS_ORIGINS=http://localhost:3000
```

### .gitignore 설정

```bash
# 환경변수 파일 (절대 커밋 금지!)
.env
.env.local
.env.*.local

# 환경변수 템플릿은 커밋 가능
# .env.example

# Python
__pycache__/
*.pyc
.venv/
venv/

# Vector DB
chroma_db/
*.db
```

## 환경별 설정 관리

### 개발 환경 (.env.development)

```bash
# 개발 환경
DEBUG=true
LOG_LEVEL=DEBUG

# 로컬 서비스
PINECONE_INDEX_NAME=dev-index
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# 빠른 테스트용 설정
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.5
```

### 프로덕션 환경 (.env.production)

```bash
# 프로덕션 환경
DEBUG=false
LOG_LEVEL=WARNING

# 프로덕션 서비스
PINECONE_INDEX_NAME=prod-index
CORS_ORIGINS=https://myapp.com

# 안정적인 설정
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.3
```

### 환경별 로딩

```python
import os
from dotenv import load_dotenv

# 환경 확인
env = os.getenv("ENV", "development")

# 환경별 .env 파일 로드
if env == "production":
    load_dotenv(".env.production")
elif env == "staging":
    load_dotenv(".env.staging")
else:
    load_dotenv(".env.development")

print(f"Running in {env} environment")
```

## FastAPI에서 환경변수 활용

### 1. 기본 사용

```python
from fastapi import FastAPI
from pydantic_settings import BaseSettings
import os

class Settings(BaseSettings):
    openai_api_key: str
    port: int = 8000
    debug: bool = False

    class Config:
        env_file = ".env"

settings = Settings()

app = FastAPI(
    title="RAG/Agent Service",
    debug=settings.debug
)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=settings.port)
```

### 2. 의존성 주입

```python
from fastapi import Depends

def get_settings():
    return Settings()

@app.get("/config")
def get_config(settings: Settings = Depends(get_settings)):
    return {
        "llm_model": settings.llm_model,
        "debug": settings.debug,
        # API 키는 노출하지 않음!
    }
```

### 3. LLM 초기화

```python
from langchain_openai import ChatOpenAI
from functools import lru_cache

@lru_cache()
def get_llm(settings: Settings = Depends(get_settings)):
    """LLM 인스턴스를 싱글톤으로 생성"""
    return ChatOpenAI(
        model=settings.llm_model,
        temperature=settings.llm_temperature,
        max_tokens=settings.llm_max_tokens,
        api_key=settings.openai_api_key
    )

@app.post("/ask")
async def ask(
    question: str,
    llm: ChatOpenAI = Depends(get_llm)
):
    result = await llm.ainvoke(question)
    return {"answer": result.content}
```

## Docker에서 환경변수

### Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# 의존성 설치
COPY pyproject.toml .
RUN pip install uv && uv pip install -r pyproject.toml

# 코드 복사
COPY . .

# 환경변수 기본값 설정 (선택사항)
ENV PORT=8000
ENV LOG_LEVEL=INFO

# 실행
CMD uvicorn app:app --host 0.0.0.0 --port ${PORT}
```

### docker-compose.yml

```yaml
version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      # .env 파일에서 로드
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - PORT=8000
    env_file:
      - .env  # .env 파일 자동 로드

  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    environment:
      - VITE_API_URL=http://localhost:8000
```

### Docker 실행 시 환경변수 전달

```bash
# 명령줄에서 전달
docker run -e OPENAI_API_KEY=sk-xxx myapp

# .env 파일 사용
docker run --env-file .env myapp

# docker-compose
docker-compose --env-file .env up
```

## AWS에서 환경변수 관리

### 1. ECS Task Definition

```json
{
  "containerDefinitions": [
    {
      "name": "backend",
      "image": "myapp:latest",
      "environment": [
        {
          "name": "PORT",
          "value": "8000"
        },
        {
          "name": "LOG_LEVEL",
          "value": "INFO"
        }
      ],
      "secrets": [
        {
          "name": "OPENAI_API_KEY",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:openai-key"
        },
        {
          "name": "PINECONE_API_KEY",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:pinecone-key"
        }
      ]
    }
  ]
}
```

### 2. AWS Secrets Manager

```python
import boto3
import json

def get_secret(secret_name):
    """AWS Secrets Manager에서 시크릿 가져오기"""
    client = boto3.client('secretsmanager', region_name='us-east-1')

    try:
        response = client.get_secret_value(SecretId=secret_name)
        return json.loads(response['SecretString'])
    except Exception as e:
        print(f"Error retrieving secret: {e}")
        return None

# 사용
secrets = get_secret('my-app-secrets')
openai_key = secrets['OPENAI_API_KEY']
```

### 3. Parameter Store

```python
import boto3

def get_parameter(name):
    """AWS Systems Manager Parameter Store에서 파라미터 가져오기"""
    ssm = boto3.client('ssm', region_name='us-east-1')

    response = ssm.get_parameter(
        Name=name,
        WithDecryption=True
    )

    return response['Parameter']['Value']

# 사용
openai_key = get_parameter('/myapp/openai-api-key')
```

## 환경변수 검증

### 시작 시 검증

```python
from pydantic_settings import BaseSettings
from pydantic import Field, validator

class Settings(BaseSettings):
    openai_api_key: str = Field(..., min_length=20)
    pinecone_api_key: str | None = None

    port: int = Field(default=8000, ge=1, le=65535)
    cors_origins: str

    @validator('openai_api_key')
    def validate_openai_key(cls, v):
        if not v.startswith('sk-'):
            raise ValueError('Invalid OpenAI API key format')
        return v

    @validator('cors_origins')
    def validate_cors_origins(cls, v):
        # URL 형식 검증
        origins = v.split(',')
        for origin in origins:
            if not origin.startswith('http'):
                raise ValueError(f'Invalid origin: {origin}')
        return v

    class Config:
        env_file = ".env"

# 검증 실패 시 에러 발생
try:
    settings = Settings()
    print("✅ All settings are valid")
except Exception as e:
    print(f"❌ Configuration error: {e}")
    exit(1)
```

### 런타임 검증

```python
@app.on_event("startup")
async def validate_configuration():
    """애플리케이션 시작 시 설정 검증"""
    errors = []

    # OpenAI API 키 검증
    if not settings.openai_api_key:
        errors.append("OPENAI_API_KEY is missing")

    # Pinecone 연결 테스트 (선택사항)
    if settings.pinecone_api_key:
        try:
            from pinecone import Pinecone
            pc = Pinecone(api_key=settings.pinecone_api_key)
            # 연결 테스트
        except Exception as e:
            errors.append(f"Pinecone connection failed: {e}")

    if errors:
        for error in errors:
            print(f"❌ {error}")
        raise RuntimeError("Configuration validation failed")

    print("✅ Configuration validated successfully")
```

## Best Practices

### 1. 환경변수 명명 규칙

```bash
# ✅ 좋은 예
OPENAI_API_KEY=xxx
DATABASE_URL=xxx
REDIS_HOST=xxx

# ❌ 나쁜 예
apiKey=xxx           # 소문자
OpenAI_Key=xxx       # 카멜케이스
OPENAI-API-KEY=xxx   # 하이픈
```

**규칙**:
- 대문자 + 언더스코어
- 명확한 이름
- 일관된 접두사 (예: `OPENAI_`, `PINECONE_`)

### 2. 기본값 제공

```python
# ✅ 좋은 예
port = int(os.getenv("PORT", "8000"))
debug = os.getenv("DEBUG", "false").lower() == "true"

# ❌ 나쁜 예
port = int(os.environ["PORT"])  # 없으면 에러
```

### 3. 타입 변환 명시

```python
# ✅ 좋은 예
max_tokens = int(os.getenv("MAX_TOKENS", "1000"))
temperature = float(os.getenv("TEMPERATURE", "0.7"))
debug = os.getenv("DEBUG", "false").lower() == "true"

# ❌ 나쁜 예
max_tokens = os.getenv("MAX_TOKENS")  # 문자열!
```

### 4. 민감 정보 로그 방지

```python
import logging

# ✅ 좋은 예
def mask_api_key(key: str) -> str:
    if not key:
        return "None"
    return f"{key[:7]}***"

logger.info(f"Using API key: {mask_api_key(settings.openai_api_key)}")

# ❌ 나쁜 예
logger.info(f"API key: {settings.openai_api_key}")  # 전체 키 노출!
```

### 5. .env 파일 버전 관리

```
✅ Git에 커밋:
- .env.example (템플릿)
- .env.template
- README.md (환경변수 설명)

❌ Git에 절대 커밋 금지:
- .env
- .env.local
- .env.production
- .env.development
```

## 보안 체크리스트

- [ ] `.env` 파일이 `.gitignore`에 포함되어 있는가?
- [ ] `.env.example`에 실제 API 키가 없는가?
- [ ] 프로덕션에서 AWS Secrets Manager를 사용하는가?
- [ ] 로그에 API 키가 노출되지 않는가?
- [ ] 환경변수 검증이 시작 시 실행되는가?
- [ ] CORS 설정이 프로덕션에 맞게 제한되어 있는가?
- [ ] DEBUG=false가 프로덕션에 설정되어 있는가?

## 트러블슈팅

### 문제: 환경변수를 읽을 수 없음

```bash
# 확인 1: .env 파일 존재 여부
ls -la .env

# 확인 2: .env 파일 내용
cat .env

# 확인 3: Python에서 확인
python -c "from dotenv import load_dotenv; import os; load_dotenv(); print(os.getenv('OPENAI_API_KEY'))"
```

### 문제: Docker에서 환경변수 인식 안 됨

```bash
# 확인 1: 환경변수 전달되었는지
docker exec <container_id> env | grep OPENAI

# 확인 2: docker-compose에서 env_file 경로
docker-compose config

# 해결: 명시적으로 전달
docker run --env-file .env myapp
```

### 문제: AWS ECS에서 시크릿 못 가져옴

```bash
# 확인 1: IAM 권한
# Task Role에 secretsmanager:GetSecretValue 권한 필요

# 확인 2: 시크릿 ARN 확인
aws secretsmanager describe-secret --secret-id my-secret

# 확인 3: 컨테이너 로그 확인
aws logs tail /ecs/my-app --follow
```

## 다음 단계

환경변수 관리를 마스터했다면:

1. **Docker/Kubernetes Secrets**: 컨테이너 환경 시크릿 관리
2. **CI/CD 환경변수**: GitHub Actions, GitLab CI 설정
3. **Vault**: HashiCorp Vault로 중앙 집중식 시크릿 관리
4. **암호화**: 환경변수 암호화 및 복호화
